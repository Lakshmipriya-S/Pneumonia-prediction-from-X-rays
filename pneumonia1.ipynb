{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea360396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation, MaxPool2D\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234996c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('chest_xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa93ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=data_dir/'train'\n",
    "test_dir=data_dir/'test'\n",
    "val_dir=data_dir/'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1522ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train=list(train_dir.glob('*/*.jpeg'))\n",
    "file_path_test=list(test_dir.glob('*/*.jpeg'))\n",
    "file_path_val=list(val_dir.glob('*/*.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85de4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path_train))\n",
    "\n",
    "label_test=list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path_test))\n",
    "\n",
    "label_val=list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ac3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=pd.Series(label_train,name='Label')\n",
    "\n",
    "label_test=pd.Series(label_test,name='Label')\n",
    "\n",
    "label_val=pd.Series(label_val,name='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868947bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train=pd.Series(file_path_train,name='Filepath').astype(str)\n",
    "\n",
    "\n",
    "img_test=pd.Series(file_path_test,name='Filepath').astype(str)\n",
    "\n",
    "\n",
    "img_val=pd.Series(file_path_val,name='Filepath').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1833a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.concat([img_train,label_train],axis=1)\n",
    "\n",
    "\n",
    "test_df=pd.concat([img_test,label_test],axis=1)\n",
    "\n",
    "\n",
    "val_df=pd.concat([img_val,label_val],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f686a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=LabelEncoder()\n",
    "train_df1=pd.DataFrame()\n",
    "test_df1=pd.DataFrame()\n",
    "val_df1=pd.DataFrame()\n",
    "\n",
    "\n",
    "train_df1[\"Label\"]=l.fit_transform(train_df[\"Label\"])\n",
    "test_df1[\"Label\"]=l.fit_transform(test_df[\"Label\"])\n",
    "val_df1[\"Label\"]=l.fit_transform(val_df[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f622dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1[\"Filepath\"]=train_df[\"Filepath\"]\n",
    "test_df1[\"Filepath\"]=test_df[\"Filepath\"]\n",
    "val_df1[\"Filepath\"]=val_df[\"Filepath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211bb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(samplewise_center= True,\n",
    "                                       samplewise_std_normalization= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5bf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image=train_gen.flow_from_directory(train_dir,\n",
    "                                          batch_size = 32,\n",
    "                                          target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e18f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image_sample = ImageDataGenerator().flow_from_dataframe(dataframe=train_df, \n",
    "#                                                               x_col=\"Filepath\", \n",
    "#                                                               y_col=\"Label\", \n",
    "#                                                               class_mode=\"binary\", \n",
    "#                                                               batch_size=100, \n",
    "#                                                               shuffle=True, \n",
    "#                                                               target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f21db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch= train_image_sample.next()\n",
    "#data_sample= batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen=ImageDataGenerator(featurewise_center=True,\n",
    "                            featurewise_std_normalization= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d10f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_gen.fit(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0d00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image=test_gen.flow_from_directory(test_dir,\n",
    "                              batch_size=32,\n",
    "                              target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d3f879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_image=test_gen.flow_from_directory(val_dir,\n",
    "                                       class_mode='binary',\n",
    "                                       shuffle=False,\n",
    "                                       target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c6ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_class_weights(labels):\n",
    "#    weight_neg = np.sum(labels)/len(labels)\n",
    "#    weight_pos= 1-weight_neg \n",
    "#    return weight_pos, weight_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57aada7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive_weights, negative_weights= get_class_weights(train_image.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a93466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_weighted_loss_binary(pos_weights, neg_weights, epsilon=1e-7):\n",
    "#    def weighted_loss(y_true, y_pred):\n",
    "#        loss = 0.0\n",
    "#        loss +=(-1*pos_weights*y_true* K.log(y_pred+epsilon)+ \\\n",
    "#            -1*neg_weights*(1-y_true)* K.log(1-y_pred+epsilon))\n",
    "#        return loss\n",
    "#    return weighted_loss#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42ac133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = DenseNet121(weights='DenseNet/DenseNet-BC-161-48-no-top.h5',include_top= False)\n",
    "#x= base_model.output\n",
    "\n",
    "#x= GlobalAveragePooling2D()(x)\n",
    "\n",
    "#predictions= Dense(units= 1, activation =\"sigmoid\")(x)\n",
    "\n",
    "#model= Model(inputs= base_model.input, outputs=predictions )\n",
    "\n",
    "#model.compile(optimizer= 'adam', loss=get_weighted_loss_binary(positive_weights, negative_weights),\n",
    "#             metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97143df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras.applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c668e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of filtered features- 32 kerenel size-(5,5)\n",
    "\n",
    "#model1=models.Sequential()\n",
    "#model1.add(Conv2D(32,(3,3),strides=(1, 1),activation='relu',padding='same', input_shape=(224, 224, 3)))\n",
    "#model1.add(Dropout(0.3))\n",
    "#model1.add(Conv2D(128,(5,5), strides=1,activation='relu',padding=\"same\"))\n",
    "\n",
    "#model1.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba08683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping_monitor = EarlyStopping(patience = 3, monitor = \"val_acc\", mode=\"max\", verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80cd93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.compile(loss=get_weighted_loss_binary(positive_weights, negative_weights),\n",
    "#             optimizer='adam',\n",
    "#             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f32bfdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a034b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.fit_generator(\n",
    "#           train_image,\n",
    "#           epochs=5,\n",
    "#           steps_per_epoch = len(train_image),\n",
    "#           validation_data=test_image,\n",
    "#           callbacks=[early_stopping_monitor]\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28d557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16843e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32,(3,3),strides=(1, 1),activation='relu',padding='same', input_shape=(224, 224, 3)))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(Conv2D(64,(3,3),strides=(1, 1) ,padding='same',activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(Conv2D(128,(3,3),strides=(1, 1),padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(Conv2D(256,(3,3),strides=(1, 1),padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "473e5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d7bfb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0756efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmipriya/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9860 - accuracy: 0.6625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmipriya/opt/anaconda3/lib/python3.8/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/Users/lakshmipriya/opt/anaconda3/lib/python3.8/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 63s 6s/step - loss: 0.9860 - accuracy: 0.6625 - val_loss: 24.2874 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.5230 - accuracy: 0.7437 - val_loss: 1.5972 - val_accuracy: 0.7821\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.2927 - accuracy: 0.8750 - val_loss: 65.0319 - val_accuracy: 0.6266\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 45s 5s/step - loss: 0.2652 - accuracy: 0.8813 - val_loss: 84.5604 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 39s 4s/step - loss: 0.2056 - accuracy: 0.9219 - val_loss: 79.6870 - val_accuracy: 0.6266\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.1227 - accuracy: 0.9469 - val_loss: 181.8852 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 64s 7s/step - loss: 0.1481 - accuracy: 0.9438 - val_loss: 196.1952 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model1.fit_generator(train_image,epochs=10,validation_data=test_image,steps_per_epoch=10,callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec33f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c5803",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "531ef4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca0b2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=VGG16(include_top=False, weights=None,input_shape=(224,224,3), pooling='avg',classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74dbb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(\"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ffc12a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ee44907",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(base_model)\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(128,activation='relu'))\n",
    "model2.add(Dense(64,activation='relu'))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "\n",
    "## Freezing the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6acfc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 800s 16s/step - loss: 0.4560 - accuracy: 0.7681 - val_loss: 0.8031 - val_accuracy: 0.8446\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 785s 16s/step - loss: 0.2036 - accuracy: 0.9262 - val_loss: 2.2446 - val_accuracy: 0.8397\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 810s 16s/step - loss: 0.1543 - accuracy: 0.9406 - val_loss: 3.2193 - val_accuracy: 0.8221\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 744s 15s/step - loss: 0.1300 - accuracy: 0.9525 - val_loss: 2.3686 - val_accuracy: 0.8702\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 800s 16s/step - loss: 0.1137 - accuracy: 0.9600 - val_loss: 2.6026 - val_accuracy: 0.8734\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 879s 18s/step - loss: 0.1183 - accuracy: 0.9506 - val_loss: 2.5307 - val_accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14402c490>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(train_image,epochs=20,validation_data=test_image,steps_per_epoch=50,callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0390303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a88c2843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /Users/lakshmipriya/opt/anaconda3/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in /Users/lakshmipriya/opt/anaconda3/lib/python3.8/site-packages (from h5py) (1.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8f50617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model2.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a81c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "model2.save_weights(\"model2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84dbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
